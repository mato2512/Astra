<div align="center">

<img src="static/static/logo.png" alt="Astra AI Logo" width="180"/>

# Astra AI

### ğŸš€ Next-Generation AI Chat Platform

**Multi-Model LLM Interface with Custom Inference Optimization**

[![GitHub Stars](https://img.shields.io/github/stars/mato2512/Astra?style=for-the-badge&logo=github)](https://github.com/mato2512/Astra)
[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge)](./LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://hub.docker.com)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)

[ğŸŒ Live Demo](https://astra.ngts.tech) â€¢ [ğŸ“š Documentation](#-documentation) â€¢ [ğŸ¤ Contributing](#-contributing) â€¢ [ğŸ’¬ Support](#-support)

</div>

---

## ğŸŒŸ Overview

**Astra AI** is a powerful, self-hosted AI chat platform that combines the flexibility of multiple LLM backends with a modern, intuitive interface. Built with performance and cost-efficiency in mind, Astra supports both **llama.cpp** for optimized inference and **Ollama** for rapid model deployment.

### Why Astra?

- ğŸ’° **90% Cost Reduction** - Self-hosted inference vs. cloud APIs
- âš¡ **High Performance** - Optimized llama.cpp integration
- ğŸ”„ **Multi-Backend** - Switch between llama.cpp and Ollama seamlessly  
- ğŸ¨ **Modern UI** - Clean, responsive interface built with SvelteKit
- ğŸ”’ **Privacy First** - Your data stays on your infrastructure
- ğŸ³ **Docker Ready** - One-command deployment

---

## âœ¨ Key Features

### ğŸ¤– Multi-Model Support
- **llama.cpp Integration** - Custom quantized models (GGUF) for optimal performance
- **Ollama Support** - Quick model switching and updates
- **OpenAI Compatible** - Works with any OpenAI-compatible API
- **Model Management** - Easy model selection and configuration

### ğŸ’¬ Advanced Chat Experience
- **Real-time Streaming** - Live response generation
- **Conversation Memory** - Persistent chat history
- **Multi-turn Dialogues** - Context-aware conversations
- **Markdown & Code** - Full syntax highlighting support

### ğŸ“š Document Intelligence
- **RAG Support** - Upload and chat with your documents
- **Multiple Formats** - PDF, DOCX, TXT, and more
- **Vector Database** - ChromaDB integration for semantic search
- **Web Scraping** - Extract and analyze web content

### ğŸ› ï¸ Extensibility
- **Custom Functions** - Python-based tool integration
- **API Endpoints** - RESTful API for integrations
- **Plugin System** - Extend functionality with custom plugins
- **Webhook Support** - Connect with external services

### ğŸ‘¥ User Management
- **Role-Based Access** - Admin, user, and custom roles
- **Authentication** - Secure login with JWT tokens
- **Multi-tenancy** - Isolated user workspaces
- **Usage Tracking** - Monitor API calls and costs

### ğŸ¨ Customization
- **Dark/Light Themes** - Multiple color schemes
- **Custom Branding** - Your logo and colors
- **Responsive Design** - Works on desktop, tablet, and mobile
- **PWA Support** - Install as native app

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Astra Frontend (SvelteKit)                â”‚
â”‚  - Modern UI with real-time updates                 â”‚
â”‚  - Model selection & conversation management        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI Backend                           â”‚
â”‚  - Request routing & authentication                 â”‚
â”‚  - RAG processing & document handling               â”‚
â”‚  - Unified API for multiple backends                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   llama.cpp       â”‚  â”‚      Ollama        â”‚
    â”‚  - GGUF models    â”‚  â”‚  - Quick models    â”‚
    â”‚  - Quantization   â”‚  â”‚  - Easy updates    â”‚
    â”‚  - High speed     â”‚  â”‚  - Model library   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

**Frontend**
- âš¡ **SvelteKit** 2.5+ - Modern reactive framework
- ğŸ¨ **Tailwind CSS** 4.0 - Utility-first styling
- ğŸ“˜ **TypeScript** 5.5+ - Type-safe development
- ğŸ”¥ **Vite** 5.4+ - Lightning-fast builds

**Backend**
- ğŸ **FastAPI** 0.118+ - High-performance Python API
- ğŸ—ƒï¸ **SQLAlchemy** 2.0+ - Modern ORM
- ğŸ” **JWT** - Secure authentication
- ğŸ“Š **ChromaDB** - Vector database for RAG

**AI/ML**
- ğŸ¦™ **llama.cpp** - Optimized LLM inference
- ğŸ¦™ **Ollama** - Model management
- ğŸ¤— **Transformers** - HuggingFace models
- ğŸ“ˆ **Sentence Transformers** - Embeddings

**Infrastructure**
- ğŸ³ **Docker** - Containerization
- ğŸ”„ **Docker Compose** - Multi-container orchestration
- ğŸŒ **Nginx** - Reverse proxy
- ğŸ”’ **Let's Encrypt** - SSL certificates

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker** & **Docker Compose** (recommended)
- **Node.js** 22+ (for development)
- **Python** 3.11+ (for development)
- **4GB+ RAM** (8GB+ recommended)

### ğŸ³ Docker Deployment (Recommended)

**1. Clone the repository**
```bash
git clone https://github.com/mato2512/Astra.git
cd Astra
```

**2. Run with Docker Compose**
```bash
# For production deployment
docker compose -f docker-compose.prod.yaml up -d

# Or for development
docker compose up -d
```

**3. Access Astra**
```
http://localhost:3000
```

That's it! ğŸ‰

### âš™ï¸ Configuration

Create a `.env` file in the backend directory:

```env
# Database
DATABASE_URL=sqlite:///data/webui.db

# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI (optional)
OPENAI_API_KEY=your_api_key_here

# Application
WEBUI_NAME=Astra AI
WEBUI_SECRET_KEY=generate_a_secure_key_here

# Authentication
ENABLE_SIGNUP=True
DEFAULT_USER_ROLE=user
```

### ğŸ”§ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OLLAMA_BASE_URL` | Ollama API endpoint | `http://localhost:11434` |
| `OPENAI_API_KEY` | OpenAI API key (optional) | - |
| `DATABASE_URL` | Database connection string | `sqlite:///data/webui.db` |
| `WEBUI_SECRET_KEY` | JWT secret key | Required |
| `ENABLE_SIGNUP` | Allow new user registration | `True` |
| `DEFAULT_USER_ROLE` | Default role for new users | `user` |

---

## ğŸ“¦ Installation Methods

### Method 1: Docker Compose (Production)

```bash
# Clone repository
git clone https://github.com/mato2512/Astra.git
cd Astra

# Start services
docker compose -f docker-compose.prod.yaml up -d

# View logs
docker compose logs -f

# Stop services
docker compose down
```

### Method 2: Local Development

**Frontend**
```bash
# Install dependencies
npm install --legacy-peer-deps

# Run development server
npm run dev
# Access: http://localhost:5173
```

**Backend**
```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run backend
cd open_webui
uvicorn main:app --host 0.0.0.0 --port 8080 --reload
# Access: http://localhost:8080
```

### Method 3: Docker Hub (Coming Soon)

```bash
docker run -d \
  -p 3000:3000 \
  -v astra-data:/app/data \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  yourusername/astra:latest
```

---

## ğŸ¯ Usage

### Setting Up Your First Model

1. **Start Ollama** (if not using Docker bundled version)
   ```bash
   ollama serve
   ```

2. **Pull a model**
   ```bash
   ollama pull llama2:7b
   # or
   ollama pull mistral:7b
   ```

3. **Access Astra** at `http://localhost:3000`

4. **Select Model** from the dropdown in the chat interface

5. **Start Chatting!** ğŸ‰

### Using llama.cpp Models

1. **Download GGUF model** from HuggingFace
   ```bash
   wget https://huggingface.co/...your-model.gguf
   ```

2. **Place in models directory**
   ```bash
   mkdir -p backend/data/models
   mv your-model.gguf backend/data/models/
   ```

3. **Configure backend** to use llama.cpp

4. **Select model** in Astra UI

### Document Chat (RAG)

1. Click **ğŸ“ Upload Document** in chat
2. Select PDF, DOCX, or TXT file
3. Use `#document-name` to reference in chat
4. Ask questions about your document!

---

## ğŸ”’ Security

- âœ… **JWT Authentication** - Secure token-based auth
- âœ… **Password Hashing** - Argon2 encryption
- âœ… **RBAC** - Role-based access control
- âœ… **CORS Protection** - Configured origins only
- âœ… **Rate Limiting** - Prevent abuse
- âœ… **SQL Injection Protection** - Parameterized queries

---

## ğŸ“Š Performance

### Benchmark Results

| Backend | Model | Tokens/sec | Response Time | Memory |
|---------|-------|-----------|---------------|---------|
| llama.cpp | Llama-2-7B-Q4 | 45-60 | ~2s | 4.8GB |
| llama.cpp | Mistral-7B-Q5 | 40-55 | ~2.5s | 5.2GB |
| Ollama | Llama-2-7B | 35-50 | ~3s | 5.5GB |
| OpenAI API | GPT-3.5 | Varies | ~1.5s | N/A |

*Tested on: Intel i7-10700, 16GB RAM, No GPU*

### Cost Comparison

| Solution | Monthly Cost (10K requests) |
|----------|---------------------------|
| **Astra (Self-hosted)** | **~$50** (server costs) |
| OpenAI GPT-3.5 | ~$200 |
| Anthropic Claude | ~$400 |
| Google Gemini | ~$150 |

**Savings: 75-90%** ğŸ’°

---

## ğŸ› ï¸ Development

### Project Structure

```
Astra/
â”œâ”€â”€ backend/                # FastAPI backend
â”‚   â”œâ”€â”€ open_webui/        # Main application
â”‚   â”‚   â”œâ”€â”€ models/        # Database models
â”‚   â”‚   â”œâ”€â”€ routers/       # API routes
â”‚   â”‚   â”œâ”€â”€ utils/         # Utilities
â”‚   â”‚   â””â”€â”€ main.py        # Entry point
â”‚   â””â”€â”€ requirements.txt   # Python deps
â”œâ”€â”€ src/                   # SvelteKit frontend
â”‚   â”œâ”€â”€ lib/              # Components
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â”œâ”€â”€ stores/       # State management
â”‚   â”‚   â””â”€â”€ utils/        # Helper functions
â”‚   â””â”€â”€ routes/           # Pages
â”œâ”€â”€ static/               # Static assets
â”œâ”€â”€ docker-compose.yaml   # Docker config
â”œâ”€â”€ Dockerfile           # Container image
â””â”€â”€ package.json         # Node.js deps
```

### Building from Source

```bash
# Clone repository
git clone https://github.com/mato2512/Astra.git
cd Astra

# Build frontend
npm install --legacy-peer-deps
npm run build

# Build Docker image
docker build -t astra:latest .

# Run container
docker run -d -p 3000:8080 astra:latest
```

### Running Tests

```bash
# Frontend tests
npm run test

# Backend tests
cd backend
pytest

# E2E tests
npm run test:e2e
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### Ways to Contribute

- ğŸ› **Report bugs** - Open an issue with details
- ğŸ’¡ **Suggest features** - Share your ideas
- ğŸ“ **Improve docs** - Help others understand
- ğŸ”§ **Submit PRs** - Fix issues or add features
- â­ **Star the repo** - Show your support!

### Contribution Process

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Code Style

- **Frontend**: Follow ESLint and Prettier configs
- **Backend**: Follow PEP 8 and use Black formatter
- **Commits**: Use conventional commit messages

---

## ğŸ“š Documentation

### Guides

- [Installation Guide](./docs/INSTALLATION.md)
- [Configuration Guide](./docs/CONFIGURATION.md)
- [API Documentation](./docs/API.md)
- [Development Guide](./docs/DEVELOPMENT.md)
- [Deployment Guide](./DIGITAL_OCEAN_SETUP.txt)

### Resources

- [Troubleshooting](./TROUBLESHOOTING.md)
- [FAQ](./docs/FAQ.md)
- [Changelog](./CHANGELOG.md)
- [Roadmap](./docs/ROADMAP.md)

---

## ğŸ—ºï¸ Roadmap

### âœ… Completed

- [x] Multi-model backend support (llama.cpp + Ollama)
- [x] Modern SvelteKit UI
- [x] RAG with document upload
- [x] User authentication and RBAC
- [x] Docker deployment
- [x] Custom branding

### ğŸš§ In Progress

- [ ] Model fine-tuning interface
- [ ] Advanced analytics dashboard
- [ ] Mobile app (React Native)
- [ ] Voice input/output
- [ ] Multi-language support

### ğŸ“‹ Planned

- [ ] Plugin marketplace
- [ ] Team collaboration features
- [ ] Advanced RAG with multiple sources
- [ ] Cost tracking per user
- [ ] API key management
- [ ] Kubernetes deployment
- [ ] Model performance comparison
- [ ] Custom model training pipeline

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](./LICENSE) file for details.

### Third-Party Licenses

This project uses code from various open-source projects. See [LICENSE_HISTORY](./LICENSE_HISTORY) for detailed attribution.

---

## ğŸ™ Acknowledgments

Special thanks to:

- **Open WebUI** - Original framework foundation
- **Ollama** - Easy LLM deployment
- **llama.cpp** - Efficient inference engine
- **SvelteKit** - Modern web framework
- **FastAPI** - High-performance Python framework
- **HuggingFace** - Model hosting and transformers
- **Open Source Community** - For amazing tools and libraries

---

## ğŸ’¬ Support

### Get Help

- ğŸ“§ **Email**: [prasad@ngts.tech](mailto:prasad@ngts.tech)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/mato2512/Astra/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/mato2512/Astra/discussions)

### Community

- â­ **Star** this repo to show support
- ğŸ”€ **Fork** to create your own version
- ğŸ“¢ **Share** with others who might benefit

---

## ğŸ“ˆ Stats

![GitHub repo size](https://img.shields.io/github/repo-size/mato2512/Astra?style=flat-square)
![GitHub language count](https://img.shields.io/github/languages/count/mato2512/Astra?style=flat-square)
![GitHub last commit](https://img.shields.io/github/last-commit/mato2512/Astra?style=flat-square)
![GitHub issues](https://img.shields.io/github/issues/mato2512/Astra?style=flat-square)
![GitHub pull requests](https://img.shields.io/github/issues-pr/mato2512/Astra?style=flat-square)

---

<div align="center">

### Built with â¤ï¸ by [Prasad Navale](https://github.com/mato2512)

**Astra AI** - Democratizing AI, One Chat at a Time

[â¬† Back to Top](#astra-ai)

---

**Â© 2025 Prasad Navale. All rights reserved.**

</div>
